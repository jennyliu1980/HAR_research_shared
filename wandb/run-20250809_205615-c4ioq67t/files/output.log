============================================================
Self-supervised Pretraining for HAR
============================================================
Dataset: ucihar
Masking: time
  Time mask: 30%
============================================================

Loading ucihar dataset...
Data shape: (6172, 128, 9)
  Samples: 6172
  Timesteps: 128
  Features: 9
  Classes: 6

Initializing model...
  Total parameters: 466,569

Starting pretraining...
  Epochs: 150
  Batch size: 256
  Learning rate: 0.001
============================================================
Training on cpu
Total batches per epoch: 25
Epoch [1/150] - Loss: 0.7493 - Time Loss: 0.7493 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [2/150] - Loss: 0.7136 - Time Loss: 0.7136 - Channel Loss: 0.0000 - Time: 16.9s
Epoch [3/150] - Loss: 0.6905 - Time Loss: 0.6905 - Channel Loss: 0.0000 - Time: 17.3s
Epoch [4/150] - Loss: 0.6920 - Time Loss: 0.6920 - Channel Loss: 0.0000 - Time: 17.7s
Epoch [5/150] - Loss: 0.6875 - Time Loss: 0.6875 - Channel Loss: 0.0000 - Time: 17.4s
Epoch [6/150] - Loss: 0.6853 - Time Loss: 0.6853 - Channel Loss: 0.0000 - Time: 17.2s
Epoch [7/150] - Loss: 0.6870 - Time Loss: 0.6870 - Channel Loss: 0.0000 - Time: 17.0s
Epoch [8/150] - Loss: 0.6910 - Time Loss: 0.6910 - Channel Loss: 0.0000 - Time: 17.8s
Epoch [9/150] - Loss: 0.6905 - Time Loss: 0.6905 - Channel Loss: 0.0000 - Time: 17.2s
Epoch [10/150] - Loss: 0.6833 - Time Loss: 0.6833 - Channel Loss: 0.0000 - Time: 17.1s
Epoch [11/150] - Loss: 0.6833 - Time Loss: 0.6833 - Channel Loss: 0.0000 - Time: 17.3s
Epoch [12/150] - Loss: 0.6929 - Time Loss: 0.6929 - Channel Loss: 0.0000 - Time: 16.9s
Epoch [13/150] - Loss: 0.6833 - Time Loss: 0.6833 - Channel Loss: 0.0000 - Time: 16.8s
Epoch [14/150] - Loss: 0.6858 - Time Loss: 0.6858 - Channel Loss: 0.0000 - Time: 17.4s
Epoch [15/150] - Loss: 0.6757 - Time Loss: 0.6757 - Channel Loss: 0.0000 - Time: 17.6s
Epoch [16/150] - Loss: 0.6762 - Time Loss: 0.6762 - Channel Loss: 0.0000 - Time: 17.9s
Epoch [17/150] - Loss: 0.6815 - Time Loss: 0.6815 - Channel Loss: 0.0000 - Time: 17.9s
Epoch [18/150] - Loss: 0.6806 - Time Loss: 0.6806 - Channel Loss: 0.0000 - Time: 18.0s
Epoch [19/150] - Loss: 0.6824 - Time Loss: 0.6824 - Channel Loss: 0.0000 - Time: 17.9s
Epoch [20/150] - Loss: 0.6696 - Time Loss: 0.6696 - Channel Loss: 0.0000 - Time: 18.9s
Epoch [21/150] - Loss: 0.6689 - Time Loss: 0.6689 - Channel Loss: 0.0000 - Time: 18.2s
Epoch [22/150] - Loss: 0.6663 - Time Loss: 0.6663 - Channel Loss: 0.0000 - Time: 17.7s
Epoch [23/150] - Loss: 0.6578 - Time Loss: 0.6578 - Channel Loss: 0.0000 - Time: 17.6s
Epoch [24/150] - Loss: 0.6697 - Time Loss: 0.6697 - Channel Loss: 0.0000 - Time: 18.2s
Epoch [25/150] - Loss: 0.6641 - Time Loss: 0.6641 - Channel Loss: 0.0000 - Time: 18.1s
Epoch [26/150] - Loss: 0.6576 - Time Loss: 0.6576 - Channel Loss: 0.0000 - Time: 17.6s
Epoch [27/150] - Loss: 0.6521 - Time Loss: 0.6521 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [28/150] - Loss: 0.6596 - Time Loss: 0.6596 - Channel Loss: 0.0000 - Time: 17.9s
Epoch [29/150] - Loss: 0.6455 - Time Loss: 0.6455 - Channel Loss: 0.0000 - Time: 17.6s
Epoch [30/150] - Loss: 0.6492 - Time Loss: 0.6492 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [31/150] - Loss: 0.6453 - Time Loss: 0.6453 - Channel Loss: 0.0000 - Time: 18.4s
Epoch [32/150] - Loss: 0.6418 - Time Loss: 0.6418 - Channel Loss: 0.0000 - Time: 17.8s
Epoch [33/150] - Loss: 0.6335 - Time Loss: 0.6335 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [34/150] - Loss: 0.6377 - Time Loss: 0.6377 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [35/150] - Loss: 0.6318 - Time Loss: 0.6318 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [36/150] - Loss: 0.6217 - Time Loss: 0.6217 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [37/150] - Loss: 0.6070 - Time Loss: 0.6070 - Channel Loss: 0.0000 - Time: 18.2s
Epoch [38/150] - Loss: 0.5779 - Time Loss: 0.5779 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [39/150] - Loss: 0.5568 - Time Loss: 0.5568 - Channel Loss: 0.0000 - Time: 18.1s
Epoch [40/150] - Loss: 0.5254 - Time Loss: 0.5254 - Channel Loss: 0.0000 - Time: 19.1s
Epoch [41/150] - Loss: 0.5036 - Time Loss: 0.5036 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [42/150] - Loss: 0.4689 - Time Loss: 0.4689 - Channel Loss: 0.0000 - Time: 18.2s
Epoch [43/150] - Loss: 0.4306 - Time Loss: 0.4306 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [44/150] - Loss: 0.4059 - Time Loss: 0.4059 - Channel Loss: 0.0000 - Time: 18.4s
Epoch [45/150] - Loss: 0.3923 - Time Loss: 0.3923 - Channel Loss: 0.0000 - Time: 17.6s
Epoch [46/150] - Loss: 0.3826 - Time Loss: 0.3826 - Channel Loss: 0.0000 - Time: 17.4s
Epoch [47/150] - Loss: 0.3633 - Time Loss: 0.3633 - Channel Loss: 0.0000 - Time: 17.4s
Epoch [48/150] - Loss: 0.3482 - Time Loss: 0.3482 - Channel Loss: 0.0000 - Time: 17.8s
Epoch [49/150] - Loss: 0.3300 - Time Loss: 0.3300 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [50/150] - Loss: 0.3359 - Time Loss: 0.3359 - Channel Loss: 0.0000 - Time: 18.1s
Epoch [51/150] - Loss: 0.3248 - Time Loss: 0.3248 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [52/150] - Loss: 0.3070 - Time Loss: 0.3070 - Channel Loss: 0.0000 - Time: 18.3s
Epoch [53/150] - Loss: 0.3048 - Time Loss: 0.3048 - Channel Loss: 0.0000 - Time: 17.8s
Epoch [54/150] - Loss: 0.2914 - Time Loss: 0.2914 - Channel Loss: 0.0000 - Time: 16.8s
Epoch [55/150] - Loss: 0.2954 - Time Loss: 0.2954 - Channel Loss: 0.0000 - Time: 16.8s
Epoch [56/150] - Loss: 0.2806 - Time Loss: 0.2806 - Channel Loss: 0.0000 - Time: 17.2s
Epoch [57/150] - Loss: 0.2704 - Time Loss: 0.2704 - Channel Loss: 0.0000 - Time: 17.4s
Epoch [58/150] - Loss: 0.2632 - Time Loss: 0.2632 - Channel Loss: 0.0000 - Time: 17.2s
Epoch [59/150] - Loss: 0.2518 - Time Loss: 0.2518 - Channel Loss: 0.0000 - Time: 17.7s
Epoch [60/150] - Loss: 0.2478 - Time Loss: 0.2478 - Channel Loss: 0.0000 - Time: 18.0s
Epoch [61/150] - Loss: 0.2396 - Time Loss: 0.2396 - Channel Loss: 0.0000 - Time: 18.0s
Epoch [62/150] - Loss: 0.2386 - Time Loss: 0.2386 - Channel Loss: 0.0000 - Time: 17.3s
Epoch [63/150] - Loss: 0.2527 - Time Loss: 0.2527 - Channel Loss: 0.0000 - Time: 16.5s
Epoch [64/150] - Loss: 0.2330 - Time Loss: 0.2330 - Channel Loss: 0.0000 - Time: 16.5s
Epoch [65/150] - Loss: 0.2212 - Time Loss: 0.2212 - Channel Loss: 0.0000 - Time: 16.0s
Epoch [66/150] - Loss: 0.2077 - Time Loss: 0.2077 - Channel Loss: 0.0000 - Time: 15.5s
Epoch [67/150] - Loss: 0.2027 - Time Loss: 0.2027 - Channel Loss: 0.0000 - Time: 15.5s
Epoch [68/150] - Loss: 0.2010 - Time Loss: 0.2010 - Channel Loss: 0.0000 - Time: 15.6s
Epoch [69/150] - Loss: 0.1970 - Time Loss: 0.1970 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [70/150] - Loss: 0.1896 - Time Loss: 0.1896 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [71/150] - Loss: 0.1820 - Time Loss: 0.1820 - Channel Loss: 0.0000 - Time: 14.8s
Epoch [72/150] - Loss: 0.1760 - Time Loss: 0.1760 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [73/150] - Loss: 0.1744 - Time Loss: 0.1744 - Channel Loss: 0.0000 - Time: 14.8s
Epoch [74/150] - Loss: 0.1727 - Time Loss: 0.1727 - Channel Loss: 0.0000 - Time: 14.5s
Epoch [75/150] - Loss: 0.1732 - Time Loss: 0.1732 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [76/150] - Loss: 0.1662 - Time Loss: 0.1662 - Channel Loss: 0.0000 - Time: 14.8s
Epoch [77/150] - Loss: 0.1590 - Time Loss: 0.1590 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [78/150] - Loss: 0.1571 - Time Loss: 0.1571 - Channel Loss: 0.0000 - Time: 14.7s
Epoch [79/150] - Loss: 0.1540 - Time Loss: 0.1540 - Channel Loss: 0.0000 - Time: 14.8s
Epoch [80/150] - Loss: 0.1542 - Time Loss: 0.1542 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [81/150] - Loss: 0.1525 - Time Loss: 0.1525 - Channel Loss: 0.0000 - Time: 14.5s
Epoch [82/150] - Loss: 0.1468 - Time Loss: 0.1468 - Channel Loss: 0.0000 - Time: 14.6s
Epoch [83/150] - Loss: 0.1445 - Time Loss: 0.1445 - Channel Loss: 0.0000 - Time: 14.8s
Epoch [84/150] - Loss: 0.1455 - Time Loss: 0.1455 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [85/150] - Loss: 0.1474 - Time Loss: 0.1474 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [86/150] - Loss: 0.1443 - Time Loss: 0.1443 - Channel Loss: 0.0000 - Time: 14.7s
Epoch [87/150] - Loss: 0.1394 - Time Loss: 0.1394 - Channel Loss: 0.0000 - Time: 14.6s
Epoch [88/150] - Loss: 0.1387 - Time Loss: 0.1387 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [89/150] - Loss: 0.1337 - Time Loss: 0.1337 - Channel Loss: 0.0000 - Time: 14.6s
Epoch [90/150] - Loss: 0.1365 - Time Loss: 0.1365 - Channel Loss: 0.0000 - Time: 14.7s
Epoch [91/150] - Loss: 0.1346 - Time Loss: 0.1346 - Channel Loss: 0.0000 - Time: 14.4s
Epoch [92/150] - Loss: 0.1335 - Time Loss: 0.1335 - Channel Loss: 0.0000 - Time: 14.5s
Epoch [93/150] - Loss: 0.1297 - Time Loss: 0.1297 - Channel Loss: 0.0000 - Time: 14.4s
Epoch [94/150] - Loss: 0.1277 - Time Loss: 0.1277 - Channel Loss: 0.0000 - Time: 14.5s
Epoch [95/150] - Loss: 0.1299 - Time Loss: 0.1299 - Channel Loss: 0.0000 - Time: 14.3s
Epoch [96/150] - Loss: 0.1260 - Time Loss: 0.1260 - Channel Loss: 0.0000 - Time: 14.5s
Epoch [97/150] - Loss: 0.1271 - Time Loss: 0.1271 - Channel Loss: 0.0000 - Time: 14.3s
Epoch [98/150] - Loss: 0.1263 - Time Loss: 0.1263 - Channel Loss: 0.0000 - Time: 14.2s
Epoch [99/150] - Loss: 0.1208 - Time Loss: 0.1208 - Channel Loss: 0.0000 - Time: 14.2s
Epoch [100/150] - Loss: 0.1229 - Time Loss: 0.1229 - Channel Loss: 0.0000 - Time: 14.3s
Epoch [101/150] - Loss: 0.1241 - Time Loss: 0.1241 - Channel Loss: 0.0000 - Time: 14.1s
Epoch [102/150] - Loss: 0.1218 - Time Loss: 0.1218 - Channel Loss: 0.0000 - Time: 14.1s
Traceback (most recent call last):
  File "main_wandb.py", line 292, in <module>
    best_loss, best_epoch = pretrain_with_wandb(model, args.dataset, x_train, args)
  File "main_wandb.py", line 203, in pretrain_with_wandb
    model_dir = save_model(
  File "C:\Users\jenny\OneDrive\Desktop\PythonProject_HAR\utils.py", line 178, in save_model
    torch.save(model, model_dir)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 652, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 864, in _save
    pickler.dump(obj)
AttributeError: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'
