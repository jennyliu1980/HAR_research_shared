============================================================
Self-supervised Pretraining for HAR
============================================================
Dataset: ucihar
Masking: time
  Time mask: 10%
============================================================

Loading ucihar dataset...
Generating UCI-HAR .npy files from raw data...
Saved UCI-HAR data:
  X shape: (10299, 128, 9) (samples, timesteps, channels)
  Y shape: (10299, 6) (samples, classes)
  Subjects: 30 unique subjects
Data shape: (6172, 128, 9)
  Samples: 6172
  Timesteps: 128
  Features: 9
  Classes: 6

Initializing model...
  Total parameters: 466,569

Starting pretraining...
  Epochs: 150
  Batch size: 256
  Learning rate: 0.001
============================================================
Training on cpu
Total batches per epoch: 25
Epoch [1/150] - Loss: 0.7514 - Time Loss: 0.7514 - Channel Loss: 0.0000 - Time: 41.7s
Epoch [2/150] - Loss: 0.7145 - Time Loss: 0.7145 - Channel Loss: 0.0000 - Time: 46.3s
Epoch [3/150] - Loss: 0.6908 - Time Loss: 0.6908 - Channel Loss: 0.0000 - Time: 44.3s
Epoch [4/150] - Loss: 0.6941 - Time Loss: 0.6941 - Channel Loss: 0.0000 - Time: 44.3s
Epoch [5/150] - Loss: 0.6916 - Time Loss: 0.6916 - Channel Loss: 0.0000 - Time: 24.5s
Epoch [6/150] - Loss: 0.6890 - Time Loss: 0.6890 - Channel Loss: 0.0000 - Time: 42.1s
Epoch [7/150] - Loss: 0.6913 - Time Loss: 0.6913 - Channel Loss: 0.0000 - Time: 42.4s
Epoch [8/150] - Loss: 0.6901 - Time Loss: 0.6901 - Channel Loss: 0.0000 - Time: 42.7s
Epoch [9/150] - Loss: 0.6854 - Time Loss: 0.6854 - Channel Loss: 0.0000 - Time: 42.0s
Epoch [10/150] - Loss: 0.6859 - Time Loss: 0.6859 - Channel Loss: 0.0000 - Time: 44.4s
Epoch [11/150] - Loss: 0.6896 - Time Loss: 0.6896 - Channel Loss: 0.0000 - Time: 44.0s
Epoch [12/150] - Loss: 0.6918 - Time Loss: 0.6918 - Channel Loss: 0.0000 - Time: 41.7s
Epoch [13/150] - Loss: 0.6882 - Time Loss: 0.6882 - Channel Loss: 0.0000 - Time: 18.0s
Epoch [14/150] - Loss: 0.6852 - Time Loss: 0.6852 - Channel Loss: 0.0000 - Time: 19.0s
Epoch [15/150] - Loss: 0.6795 - Time Loss: 0.6795 - Channel Loss: 0.0000 - Time: 18.7s
Epoch [16/150] - Loss: 0.6807 - Time Loss: 0.6807 - Channel Loss: 0.0000 - Time: 19.4s
Epoch [17/150] - Loss: 0.6943 - Time Loss: 0.6943 - Channel Loss: 0.0000 - Time: 19.2s
Epoch [18/150] - Loss: 0.6832 - Time Loss: 0.6832 - Channel Loss: 0.0000 - Time: 19.1s
Epoch [19/150] - Loss: 0.6939 - Time Loss: 0.6939 - Channel Loss: 0.0000 - Time: 18.5s
Epoch [20/150] - Loss: 0.6770 - Time Loss: 0.6770 - Channel Loss: 0.0000 - Time: 19.5s
Epoch [21/150] - Loss: 0.6823 - Time Loss: 0.6823 - Channel Loss: 0.0000 - Time: 19.7s
Epoch [22/150] - Loss: 0.6806 - Time Loss: 0.6806 - Channel Loss: 0.0000 - Time: 19.6s
Epoch [23/150] - Loss: 0.6749 - Time Loss: 0.6749 - Channel Loss: 0.0000 - Time: 18.6s
Epoch [24/150] - Loss: 0.6905 - Time Loss: 0.6905 - Channel Loss: 0.0000 - Time: 18.9s
Epoch [25/150] - Loss: 0.6763 - Time Loss: 0.6763 - Channel Loss: 0.0000 - Time: 19.2s
Epoch [26/150] - Loss: 0.6721 - Time Loss: 0.6721 - Channel Loss: 0.0000 - Time: 19.5s
Epoch [27/150] - Loss: 0.6667 - Time Loss: 0.6667 - Channel Loss: 0.0000 - Time: 19.7s
Epoch [28/150] - Loss: 0.6754 - Time Loss: 0.6754 - Channel Loss: 0.0000 - Time: 19.4s
Epoch [29/150] - Loss: 0.6640 - Time Loss: 0.6640 - Channel Loss: 0.0000 - Time: 19.1s
Epoch [30/150] - Loss: 0.6624 - Time Loss: 0.6624 - Channel Loss: 0.0000 - Time: 26.7s
Epoch [31/150] - Loss: 0.6709 - Time Loss: 0.6709 - Channel Loss: 0.0000 - Time: 47.0s
Epoch [32/150] - Loss: 0.6642 - Time Loss: 0.6642 - Channel Loss: 0.0000 - Time: 47.6s
Epoch [33/150] - Loss: 0.6541 - Time Loss: 0.6541 - Channel Loss: 0.0000 - Time: 45.1s
Epoch [34/150] - Loss: 0.6622 - Time Loss: 0.6622 - Channel Loss: 0.0000 - Time: 46.2s
Epoch [35/150] - Loss: 0.6596 - Time Loss: 0.6596 - Channel Loss: 0.0000 - Time: 46.5s
Epoch [36/150] - Loss: 0.6607 - Time Loss: 0.6607 - Channel Loss: 0.0000 - Time: 46.7s
Epoch [37/150] - Loss: 0.6603 - Time Loss: 0.6603 - Channel Loss: 0.0000 - Time: 46.9s
Epoch [38/150] - Loss: 0.6597 - Time Loss: 0.6597 - Channel Loss: 0.0000 - Time: 46.3s
Epoch [39/150] - Loss: 0.6650 - Time Loss: 0.6650 - Channel Loss: 0.0000 - Time: 46.6s
Epoch [40/150] - Loss: 0.6572 - Time Loss: 0.6572 - Channel Loss: 0.0000 - Time: 50.7s
Epoch [41/150] - Loss: 0.6514 - Time Loss: 0.6514 - Channel Loss: 0.0000 - Time: 49.5s
Epoch [42/150] - Loss: 0.6543 - Time Loss: 0.6543 - Channel Loss: 0.0000 - Time: 50.5s
Epoch [43/150] - Loss: 0.6447 - Time Loss: 0.6447 - Channel Loss: 0.0000 - Time: 48.7s
Epoch [44/150] - Loss: 0.6476 - Time Loss: 0.6476 - Channel Loss: 0.0000 - Time: 49.1s
Epoch [45/150] - Loss: 0.6440 - Time Loss: 0.6440 - Channel Loss: 0.0000 - Time: 49.6s
Epoch [46/150] - Loss: 0.6562 - Time Loss: 0.6562 - Channel Loss: 0.0000 - Time: 50.1s
Epoch [47/150] - Loss: 0.6360 - Time Loss: 0.6360 - Channel Loss: 0.0000 - Time: 49.1s
Epoch [48/150] - Loss: 0.6301 - Time Loss: 0.6301 - Channel Loss: 0.0000 - Time: 48.7s
Epoch [49/150] - Loss: 0.6156 - Time Loss: 0.6156 - Channel Loss: 0.0000 - Time: 47.1s
Epoch [50/150] - Loss: 0.6137 - Time Loss: 0.6137 - Channel Loss: 0.0000 - Time: 46.9s
Epoch [51/150] - Loss: 0.6016 - Time Loss: 0.6016 - Channel Loss: 0.0000 - Time: 45.9s
Epoch [52/150] - Loss: 0.5621 - Time Loss: 0.5621 - Channel Loss: 0.0000 - Time: 48.0s
Epoch [53/150] - Loss: 0.5626 - Time Loss: 0.5626 - Channel Loss: 0.0000 - Time: 47.0s
Epoch [54/150] - Loss: 0.5348 - Time Loss: 0.5348 - Channel Loss: 0.0000 - Time: 48.3s
Epoch [55/150] - Loss: 0.5448 - Time Loss: 0.5448 - Channel Loss: 0.0000 - Time: 47.5s
Epoch [56/150] - Loss: 0.5202 - Time Loss: 0.5202 - Channel Loss: 0.0000 - Time: 47.9s
Epoch [57/150] - Loss: 0.4834 - Time Loss: 0.4834 - Channel Loss: 0.0000 - Time: 46.2s
Epoch [58/150] - Loss: 0.4593 - Time Loss: 0.4593 - Channel Loss: 0.0000 - Time: 47.7s
Epoch [59/150] - Loss: 0.4529 - Time Loss: 0.4529 - Channel Loss: 0.0000 - Time: 48.2s
Epoch [60/150] - Loss: 0.4221 - Time Loss: 0.4221 - Channel Loss: 0.0000 - Time: 48.2s
Epoch [61/150] - Loss: 0.4033 - Time Loss: 0.4033 - Channel Loss: 0.0000 - Time: 47.8s
Epoch [62/150] - Loss: 0.4009 - Time Loss: 0.4009 - Channel Loss: 0.0000 - Time: 47.9s
Epoch [63/150] - Loss: 0.4011 - Time Loss: 0.4011 - Channel Loss: 0.0000 - Time: 47.8s
Epoch [64/150] - Loss: 0.3788 - Time Loss: 0.3788 - Channel Loss: 0.0000 - Time: 48.0s
Epoch [65/150] - Loss: 0.3591 - Time Loss: 0.3591 - Channel Loss: 0.0000 - Time: 47.8s
Epoch [66/150] - Loss: 0.3455 - Time Loss: 0.3455 - Channel Loss: 0.0000 - Time: 48.7s
Epoch [67/150] - Loss: 0.3385 - Time Loss: 0.3385 - Channel Loss: 0.0000 - Time: 48.2s
Epoch [68/150] - Loss: 0.3289 - Time Loss: 0.3289 - Channel Loss: 0.0000 - Time: 47.2s
Epoch [69/150] - Loss: 0.3154 - Time Loss: 0.3154 - Channel Loss: 0.0000 - Time: 47.7s
Epoch [70/150] - Loss: 0.3072 - Time Loss: 0.3072 - Channel Loss: 0.0000 - Time: 48.3s
Epoch [71/150] - Loss: 0.2967 - Time Loss: 0.2967 - Channel Loss: 0.0000 - Time: 49.0s
Epoch [72/150] - Loss: 0.2890 - Time Loss: 0.2890 - Channel Loss: 0.0000 - Time: 49.1s
Epoch [73/150] - Loss: 0.2835 - Time Loss: 0.2835 - Channel Loss: 0.0000 - Time: 49.0s
Epoch [74/150] - Loss: 0.2751 - Time Loss: 0.2751 - Channel Loss: 0.0000 - Time: 48.0s
Epoch [75/150] - Loss: 0.2746 - Time Loss: 0.2746 - Channel Loss: 0.0000 - Time: 47.7s
Epoch [76/150] - Loss: 0.2612 - Time Loss: 0.2612 - Channel Loss: 0.0000 - Time: 46.4s
Epoch [77/150] - Loss: 0.2592 - Time Loss: 0.2592 - Channel Loss: 0.0000 - Time: 46.9s
Epoch [78/150] - Loss: 0.2479 - Time Loss: 0.2479 - Channel Loss: 0.0000 - Time: 45.4s
Epoch [79/150] - Loss: 0.2430 - Time Loss: 0.2430 - Channel Loss: 0.0000 - Time: 45.3s
Epoch [80/150] - Loss: 0.2353 - Time Loss: 0.2353 - Channel Loss: 0.0000 - Time: 45.7s
Epoch [81/150] - Loss: 0.2302 - Time Loss: 0.2302 - Channel Loss: 0.0000 - Time: 44.6s
Epoch [82/150] - Loss: 0.2252 - Time Loss: 0.2252 - Channel Loss: 0.0000 - Time: 44.9s
Epoch [83/150] - Loss: 0.2176 - Time Loss: 0.2176 - Channel Loss: 0.0000 - Time: 44.7s
Epoch [84/150] - Loss: 0.2124 - Time Loss: 0.2124 - Channel Loss: 0.0000 - Time: 43.9s
Epoch [85/150] - Loss: 0.2143 - Time Loss: 0.2143 - Channel Loss: 0.0000 - Time: 43.5s
Epoch [86/150] - Loss: 0.1985 - Time Loss: 0.1985 - Channel Loss: 0.0000 - Time: 42.6s
Epoch [87/150] - Loss: 0.1893 - Time Loss: 0.1893 - Channel Loss: 0.0000 - Time: 41.9s
Epoch [88/150] - Loss: 0.1964 - Time Loss: 0.1964 - Channel Loss: 0.0000 - Time: 42.7s
Epoch [89/150] - Loss: 0.1892 - Time Loss: 0.1892 - Channel Loss: 0.0000 - Time: 42.0s
Epoch [90/150] - Loss: 0.1773 - Time Loss: 0.1773 - Channel Loss: 0.0000 - Time: 41.9s
Epoch [91/150] - Loss: 0.1720 - Time Loss: 0.1720 - Channel Loss: 0.0000 - Time: 40.8s
Epoch [92/150] - Loss: 0.1755 - Time Loss: 0.1755 - Channel Loss: 0.0000 - Time: 40.6s
Epoch [93/150] - Loss: 0.1656 - Time Loss: 0.1656 - Channel Loss: 0.0000 - Time: 40.4s
Epoch [94/150] - Loss: 0.1582 - Time Loss: 0.1582 - Channel Loss: 0.0000 - Time: 40.3s
Epoch [95/150] - Loss: 0.1624 - Time Loss: 0.1624 - Channel Loss: 0.0000 - Time: 38.6s
Epoch [96/150] - Loss: 0.1657 - Time Loss: 0.1657 - Channel Loss: 0.0000 - Time: 37.6s
Epoch [97/150] - Loss: 0.1553 - Time Loss: 0.1553 - Channel Loss: 0.0000 - Time: 37.3s
Epoch [98/150] - Loss: 0.1499 - Time Loss: 0.1499 - Channel Loss: 0.0000 - Time: 38.0s
Epoch [99/150] - Loss: 0.1462 - Time Loss: 0.1462 - Channel Loss: 0.0000 - Time: 38.2s
Epoch [100/150] - Loss: 0.1489 - Time Loss: 0.1489 - Channel Loss: 0.0000 - Time: 37.6s
Epoch [101/150] - Loss: 0.1407 - Time Loss: 0.1407 - Channel Loss: 0.0000 - Time: 37.3s
Epoch [102/150] - Loss: 0.1414 - Time Loss: 0.1414 - Channel Loss: 0.0000 - Time: 37.2s
Traceback (most recent call last):
  File "main_wandb.py", line 292, in <module>
    best_loss, best_epoch = pretrain_with_wandb(model, args.dataset, x_train, args)
  File "main_wandb.py", line 203, in pretrain_with_wandb
    model_dir = save_model(
  File "C:\Users\jenny\OneDrive\Desktop\PythonProject_HAR\utils.py", line 178, in save_model
    torch.save(model, model_dir)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 652, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 864, in _save
    pickler.dump(obj)
AttributeError: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'
