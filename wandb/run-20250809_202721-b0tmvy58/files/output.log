============================================================
Self-supervised Pretraining for HAR
============================================================
Dataset: ucihar
Masking: time
  Time mask: 20%
============================================================

Loading ucihar dataset...
Data shape: (6172, 128, 9)
  Samples: 6172
  Timesteps: 128
  Features: 9
  Classes: 6

Initializing model...
  Total parameters: 466,569

Starting pretraining...
  Epochs: 150
  Batch size: 256
  Learning rate: 0.001
============================================================
Training on cpu
Total batches per epoch: 25
Epoch [1/150] - Loss: 0.7515 - Time Loss: 0.7515 - Channel Loss: 0.0000 - Time: 35.4s
Epoch [2/150] - Loss: 0.7141 - Time Loss: 0.7141 - Channel Loss: 0.0000 - Time: 36.1s
Epoch [3/150] - Loss: 0.6909 - Time Loss: 0.6909 - Channel Loss: 0.0000 - Time: 36.8s
Epoch [4/150] - Loss: 0.6930 - Time Loss: 0.6930 - Channel Loss: 0.0000 - Time: 37.5s
Epoch [5/150] - Loss: 0.6879 - Time Loss: 0.6879 - Channel Loss: 0.0000 - Time: 36.4s
Epoch [6/150] - Loss: 0.6856 - Time Loss: 0.6856 - Channel Loss: 0.0000 - Time: 37.6s
Epoch [7/150] - Loss: 0.6873 - Time Loss: 0.6873 - Channel Loss: 0.0000 - Time: 38.2s
Epoch [8/150] - Loss: 0.6911 - Time Loss: 0.6911 - Channel Loss: 0.0000 - Time: 21.0s
Epoch [9/150] - Loss: 0.6892 - Time Loss: 0.6892 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [10/150] - Loss: 0.6829 - Time Loss: 0.6829 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [11/150] - Loss: 0.6847 - Time Loss: 0.6847 - Channel Loss: 0.0000 - Time: 15.6s
Epoch [12/150] - Loss: 0.6930 - Time Loss: 0.6930 - Channel Loss: 0.0000 - Time: 15.5s
Epoch [13/150] - Loss: 0.6848 - Time Loss: 0.6848 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [14/150] - Loss: 0.6875 - Time Loss: 0.6875 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [15/150] - Loss: 0.6758 - Time Loss: 0.6758 - Channel Loss: 0.0000 - Time: 15.8s
Epoch [16/150] - Loss: 0.6777 - Time Loss: 0.6777 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [17/150] - Loss: 0.6890 - Time Loss: 0.6890 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [18/150] - Loss: 0.6816 - Time Loss: 0.6816 - Channel Loss: 0.0000 - Time: 15.8s
Epoch [19/150] - Loss: 0.6868 - Time Loss: 0.6868 - Channel Loss: 0.0000 - Time: 16.0s
Epoch [20/150] - Loss: 0.6747 - Time Loss: 0.6747 - Channel Loss: 0.0000 - Time: 15.7s
Epoch [21/150] - Loss: 0.6783 - Time Loss: 0.6783 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [22/150] - Loss: 0.6702 - Time Loss: 0.6702 - Channel Loss: 0.0000 - Time: 16.6s
Epoch [23/150] - Loss: 0.6643 - Time Loss: 0.6643 - Channel Loss: 0.0000 - Time: 16.0s
Epoch [24/150] - Loss: 0.6803 - Time Loss: 0.6803 - Channel Loss: 0.0000 - Time: 16.8s
Epoch [25/150] - Loss: 0.6785 - Time Loss: 0.6785 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [26/150] - Loss: 0.6679 - Time Loss: 0.6679 - Channel Loss: 0.0000 - Time: 16.9s
Epoch [27/150] - Loss: 0.6625 - Time Loss: 0.6625 - Channel Loss: 0.0000 - Time: 16.6s
Epoch [28/150] - Loss: 0.6662 - Time Loss: 0.6662 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [29/150] - Loss: 0.6547 - Time Loss: 0.6547 - Channel Loss: 0.0000 - Time: 16.5s
Epoch [30/150] - Loss: 0.6518 - Time Loss: 0.6518 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [31/150] - Loss: 0.6546 - Time Loss: 0.6546 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [32/150] - Loss: 0.6532 - Time Loss: 0.6532 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [33/150] - Loss: 0.6407 - Time Loss: 0.6407 - Channel Loss: 0.0000 - Time: 16.7s
Epoch [34/150] - Loss: 0.6437 - Time Loss: 0.6437 - Channel Loss: 0.0000 - Time: 15.5s
Epoch [35/150] - Loss: 0.6450 - Time Loss: 0.6450 - Channel Loss: 0.0000 - Time: 16.7s
Epoch [36/150] - Loss: 0.6439 - Time Loss: 0.6439 - Channel Loss: 0.0000 - Time: 15.9s
Epoch [37/150] - Loss: 0.6399 - Time Loss: 0.6399 - Channel Loss: 0.0000 - Time: 16.4s
Epoch [38/150] - Loss: 0.6283 - Time Loss: 0.6283 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [39/150] - Loss: 0.6222 - Time Loss: 0.6222 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [40/150] - Loss: 0.6059 - Time Loss: 0.6059 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [41/150] - Loss: 0.5935 - Time Loss: 0.5935 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [42/150] - Loss: 0.5571 - Time Loss: 0.5571 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [43/150] - Loss: 0.5319 - Time Loss: 0.5319 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [44/150] - Loss: 0.5126 - Time Loss: 0.5126 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [45/150] - Loss: 0.4934 - Time Loss: 0.4934 - Channel Loss: 0.0000 - Time: 15.7s
Epoch [46/150] - Loss: 0.4749 - Time Loss: 0.4749 - Channel Loss: 0.0000 - Time: 16.6s
Epoch [47/150] - Loss: 0.4403 - Time Loss: 0.4403 - Channel Loss: 0.0000 - Time: 15.6s
Epoch [48/150] - Loss: 0.4168 - Time Loss: 0.4168 - Channel Loss: 0.0000 - Time: 16.4s
Epoch [49/150] - Loss: 0.3967 - Time Loss: 0.3967 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [50/150] - Loss: 0.3903 - Time Loss: 0.3903 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [51/150] - Loss: 0.3741 - Time Loss: 0.3741 - Channel Loss: 0.0000 - Time: 16.0s
Epoch [52/150] - Loss: 0.3472 - Time Loss: 0.3472 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [53/150] - Loss: 0.3465 - Time Loss: 0.3465 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [54/150] - Loss: 0.3279 - Time Loss: 0.3279 - Channel Loss: 0.0000 - Time: 16.0s
Epoch [55/150] - Loss: 0.3361 - Time Loss: 0.3361 - Channel Loss: 0.0000 - Time: 15.9s
Epoch [56/150] - Loss: 0.3163 - Time Loss: 0.3163 - Channel Loss: 0.0000 - Time: 16.6s
Epoch [57/150] - Loss: 0.2992 - Time Loss: 0.2992 - Channel Loss: 0.0000 - Time: 16.4s
Epoch [58/150] - Loss: 0.2868 - Time Loss: 0.2868 - Channel Loss: 0.0000 - Time: 15.9s
Epoch [59/150] - Loss: 0.2776 - Time Loss: 0.2776 - Channel Loss: 0.0000 - Time: 16.2s
Epoch [60/150] - Loss: 0.2700 - Time Loss: 0.2700 - Channel Loss: 0.0000 - Time: 15.3s
Epoch [61/150] - Loss: 0.2636 - Time Loss: 0.2636 - Channel Loss: 0.0000 - Time: 17.0s
Epoch [62/150] - Loss: 0.2678 - Time Loss: 0.2678 - Channel Loss: 0.0000 - Time: 16.7s
Epoch [63/150] - Loss: 0.2793 - Time Loss: 0.2793 - Channel Loss: 0.0000 - Time: 16.2s
Epoch [64/150] - Loss: 0.2557 - Time Loss: 0.2557 - Channel Loss: 0.0000 - Time: 16.4s
Epoch [65/150] - Loss: 0.2419 - Time Loss: 0.2419 - Channel Loss: 0.0000 - Time: 16.3s
Epoch [66/150] - Loss: 0.2353 - Time Loss: 0.2353 - Channel Loss: 0.0000 - Time: 16.1s
Epoch [67/150] - Loss: 0.2237 - Time Loss: 0.2237 - Channel Loss: 0.0000 - Time: 15.7s
Epoch [68/150] - Loss: 0.2205 - Time Loss: 0.2205 - Channel Loss: 0.0000 - Time: 15.7s
Epoch [69/150] - Loss: 0.2178 - Time Loss: 0.2178 - Channel Loss: 0.0000 - Time: 15.8s
Epoch [70/150] - Loss: 0.2088 - Time Loss: 0.2088 - Channel Loss: 0.0000 - Time: 15.4s
Epoch [71/150] - Loss: 0.2022 - Time Loss: 0.2022 - Channel Loss: 0.0000 - Time: 15.2s
Epoch [72/150] - Loss: 0.1947 - Time Loss: 0.1947 - Channel Loss: 0.0000 - Time: 14.6s
Epoch [73/150] - Loss: 0.1918 - Time Loss: 0.1918 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [74/150] - Loss: 0.1853 - Time Loss: 0.1853 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [75/150] - Loss: 0.1812 - Time Loss: 0.1812 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [76/150] - Loss: 0.1757 - Time Loss: 0.1757 - Channel Loss: 0.0000 - Time: 14.7s
Epoch [77/150] - Loss: 0.1718 - Time Loss: 0.1718 - Channel Loss: 0.0000 - Time: 15.1s
Epoch [78/150] - Loss: 0.1645 - Time Loss: 0.1645 - Channel Loss: 0.0000 - Time: 14.7s
Epoch [79/150] - Loss: 0.1621 - Time Loss: 0.1621 - Channel Loss: 0.0000 - Time: 14.3s
Epoch [80/150] - Loss: 0.1584 - Time Loss: 0.1584 - Channel Loss: 0.0000 - Time: 14.0s
Epoch [81/150] - Loss: 0.1558 - Time Loss: 0.1558 - Channel Loss: 0.0000 - Time: 13.7s
Epoch [82/150] - Loss: 0.1497 - Time Loss: 0.1497 - Channel Loss: 0.0000 - Time: 14.3s
Epoch [83/150] - Loss: 0.1457 - Time Loss: 0.1457 - Channel Loss: 0.0000 - Time: 15.0s
Epoch [84/150] - Loss: 0.1444 - Time Loss: 0.1444 - Channel Loss: 0.0000 - Time: 14.9s
Epoch [85/150] - Loss: 0.1464 - Time Loss: 0.1464 - Channel Loss: 0.0000 - Time: 13.2s
Epoch [86/150] - Loss: 0.1457 - Time Loss: 0.1457 - Channel Loss: 0.0000 - Time: 13.4s
Epoch [87/150] - Loss: 0.1378 - Time Loss: 0.1378 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [88/150] - Loss: 0.1349 - Time Loss: 0.1349 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [89/150] - Loss: 0.1324 - Time Loss: 0.1324 - Channel Loss: 0.0000 - Time: 13.2s
Epoch [90/150] - Loss: 0.1326 - Time Loss: 0.1326 - Channel Loss: 0.0000 - Time: 13.2s
Epoch [91/150] - Loss: 0.1275 - Time Loss: 0.1275 - Channel Loss: 0.0000 - Time: 13.0s
Epoch [92/150] - Loss: 0.1261 - Time Loss: 0.1261 - Channel Loss: 0.0000 - Time: 13.1s
Epoch [93/150] - Loss: 0.1246 - Time Loss: 0.1246 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [94/150] - Loss: 0.1236 - Time Loss: 0.1236 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [95/150] - Loss: 0.1279 - Time Loss: 0.1279 - Channel Loss: 0.0000 - Time: 13.2s
Epoch [96/150] - Loss: 0.1293 - Time Loss: 0.1293 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [97/150] - Loss: 0.1259 - Time Loss: 0.1259 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [98/150] - Loss: 0.1263 - Time Loss: 0.1263 - Channel Loss: 0.0000 - Time: 13.3s
Epoch [99/150] - Loss: 0.1170 - Time Loss: 0.1170 - Channel Loss: 0.0000 - Time: 13.4s
Epoch [100/150] - Loss: 0.1198 - Time Loss: 0.1198 - Channel Loss: 0.0000 - Time: 13.2s
Epoch [101/150] - Loss: 0.1145 - Time Loss: 0.1145 - Channel Loss: 0.0000 - Time: 13.5s
Epoch [102/150] - Loss: 0.1134 - Time Loss: 0.1134 - Channel Loss: 0.0000 - Time: 13.7s
Traceback (most recent call last):
  File "main_wandb.py", line 292, in <module>
    best_loss, best_epoch = pretrain_with_wandb(model, args.dataset, x_train, args)
  File "main_wandb.py", line 203, in pretrain_with_wandb
    model_dir = save_model(
  File "C:\Users\jenny\OneDrive\Desktop\PythonProject_HAR\utils.py", line 178, in save_model
    torch.save(model, model_dir)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 652, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "C:\Users\jenny\miniconda3\envs\maskcae\lib\site-packages\torch\serialization.py", line 864, in _save
    pickler.dump(obj)
AttributeError: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'
